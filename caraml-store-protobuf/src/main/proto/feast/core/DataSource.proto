syntax = "proto3";
package feast.core;

option go_package = "github.com/caraml-dev/caraml-store/caraml-store-sdk/go/protos/feast/core";
option java_outer_classname = "DataSourceProto";
option java_package = "dev.caraml.store.protobuf.core";

import "feast/core/DataFormat.proto";
import "feast/core/SparkOverride.proto";

// Defines a Data Source that can be used source Feature data
message DataSource {
  // Type of Data Source.
  enum SourceType {
    INVALID = 0;
    BATCH_FILE = 1;
    BATCH_BIGQUERY = 2;
    STREAM_KAFKA = 3;
    BATCH_MAXCOMPUTE = 4;
  }
  SourceType type = 1;

  // Defines mapping between fields in the sourced data 
  // and fields in parent FeatureTable.
  map<string, string> field_mapping = 2;

  // Must specify event timestamp column name
  string event_timestamp_column = 3;

  // (Optional) Specify partition column
  // useful for file sources
  string date_partition_column = 4;

  // Must specify creation timestamp column name
  string created_timestamp_column = 5;

  // Defines options for DataSource that sources features from a file
  message FileOptions {
    FileFormat file_format = 1;

    // Target URL of file to retrieve and source features from.
    // s3://path/to/file for AWS S3 storage
    // gs://path/to/file for GCP GCS storage
    // file:///path/to/file for local storage
    string file_url  = 2;

    // Allow users to override some configuration for the ingestion jobs.
    SparkOverride spark_override = 3;
  }

  // Defines options for DataSource that sources features from a BigQuery Query
  message BigQueryOptions {
    // Full table reference in the form of [project:dataset.table]
    string table_ref = 1;

    // Allow users to override some configuration for the ingestion jobs.
    SparkOverride spark_override = 2;
  }

  // Defines options for DataSource that sources features from a MaxCompute Query
  message MaxComputeOptions {
    string table_ref = 1;
  }

  // Defines options for DataSource that sources features from Kafka messages.
  // Each message should be a Protobuf that can be decoded with the generated
  // Java Protobuf class at the given class path
  message KafkaOptions {
    // Comma separated list of Kafka bootstrap servers. Used for feature tables without a defined source host[:port]]
    string bootstrap_servers = 1;

    // Kafka topic to collect feature data from.
    string topic = 2;

    // Defines the stream data format encoding feature/entity data in Kafka messages.
    StreamFormat message_format = 3;

    // Allow users to override some configuration for the ingestion jobs.
    SparkOverride spark_override = 4;
  }

  // DataSource options.
  oneof options {
    FileOptions file_options = 11;
    BigQueryOptions bigquery_options = 12;
    KafkaOptions kafka_options = 13;
    MaxComputeOptions maxcompute_options = 14;
  }
}
